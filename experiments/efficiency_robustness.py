# experiments/efficiency_robustness.py
"""
æ•ˆç‡ä¸é²æ£’æ€§éªŒè¯å®éªŒè„šæœ¬
æ ¸å¿ƒç›®æ ‡ï¼š
1. é‡åŒ–éªŒè¯è”é‚¦å­¦ä¹ ç®—æ³•çš„æ•ˆç‡æŒ‡æ ‡ï¼š
   - æ—¶é—´æ•ˆç‡ï¼šæ€»è®­ç»ƒè€—æ—¶ã€æ¯è½®è€—æ—¶ã€æ¯å®¢æˆ·ç«¯å¹³å‡è€—æ—¶ï¼›
   - èµ„æºæ•ˆç‡ï¼šå†…å­˜å ç”¨ã€GPUæ˜¾å­˜å ç”¨ï¼ˆå¦‚æœ‰ï¼‰ã€CPUä½¿ç”¨ç‡ï¼›
   - é€šä¿¡æ•ˆç‡ï¼šæ¯è½®å‚æ•°ä¼ è¾“é‡ã€æ€»é€šä¿¡å¼€é”€ï¼›
2. éªŒè¯ç®—æ³•çš„é²æ£’æ€§ï¼ˆé‡ç‚¹SAè´¡çŒ®åº¦çš„ç¨³å®šæ€§ï¼‰ï¼š
   - è§„æ¨¡é²æ£’æ€§ï¼šä¸åŒå®¢æˆ·ç«¯æ•°é‡ï¼ˆå°‘/ä¸­/å¤šï¼‰ä¸‹çš„æ€§èƒ½ç¨³å®šæ€§ï¼›
   - å™ªå£°é²æ£’æ€§ï¼šä¸åŒæ•°æ®å™ªå£°ï¼ˆæ— /ä½/é«˜ï¼‰ä¸‹çš„æ€§èƒ½ä¿æŒç‡ï¼›
   - æ•…éšœé²æ£’æ€§ï¼šèŠ‚ç‚¹æ•…éšœï¼ˆ0%/10%/20%ï¼‰ä¸‹çš„æ€§èƒ½å®¹å¿åº¦ï¼›
   - å¼‚æ„é²æ£’æ€§ï¼šä¸åŒæ•°æ®å¼‚æ„ç¨‹åº¦ä¸‹çš„æ€§èƒ½æ³¢åŠ¨ï¼›
3. å¯¹æ¯”7å¤§ç®—æ³•ï¼ˆå«ä½ çš„FedFairADP-ALAï¼‰ï¼Œæ˜ç¡®SAè´¡çŒ®åº¦+ä½ çš„æ–¹æ³•åœ¨æ•ˆç‡-é²æ£’æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚
è®¾è®¡åŸåˆ™ï¼š
- å¤šåœºæ™¯éªŒè¯é²æ£’æ€§ï¼Œè¦†ç›–è”é‚¦å­¦ä¹ å®é™…éƒ¨ç½²çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼›
- é‡åŒ–æ•ˆç‡æŒ‡æ ‡ï¼Œå…¼é¡¾æ—¶é—´/èµ„æº/é€šä¿¡ç»´åº¦ï¼›
- èšç„¦SAè´¡çŒ®åº¦+FedFairADP-ALAçš„ç¨³å®šæ€§ï¼Œå¯¹æ¯”å…¶ä¸å…¶ä»–ç®—æ³•çš„é²æ£’æ€§å·®å¼‚ï¼›
- å¤ç”¨ç°æœ‰å®éªŒæ¡†æ¶ï¼Œä¿è¯ç»“æœå¯å¯¹æ¯”æ€§ã€‚
"""
import os
import time
import json
import psutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import random
from typing import Dict, List, Tuple

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from configs.config_loader import load_config
from baselines import (
    FedAvgServer, FedAvgClient,
    DPFedAvgServer, DPFedAvgClient,
    FedProxServer, FedProxClient,
    DITTOServer, DITTOClient,
    FedShapServer, FedShapClient,
    FedAdaptiveDPServer, FedAdaptiveDPClient  # FedAdaClip++
)
# å¯¼å…¥ä½ çš„æ ¸å¿ƒè”é‚¦è®­ç»ƒå™¨ï¼ˆæ›¿ä»£å•ç‹¬çš„Server/Clientï¼‰
from core.federated.trainer import FederatedTrainer
from datasets.non_iid_partitioner import NonIIDPartitioner as simulate_data_heterogeneity
from core.noise import add_noise_to_dataset  # æ•°æ®å™ªå£°æ·»åŠ æ¨¡å—

# å¯è§†åŒ–é…ç½®
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False
PLOT_FORMAT = "png"
PLOT_DPI = 300
ALGORITHM_COLORS = {
    "FedAvg": "#1f77b4",
    "DP-FedAvg": "#ff7f0e",
    "FedProx": "#2ca02c",
    "Ditto": "#d62728",
    "FedShap": "#9467bd",  # SAè´¡çŒ®åº¦ç®—æ³•
    "FedAdaClip++": "#8c564b",  # 2024æ–°åŸºçº¿
    "FedFairADP-ALA": "#e377c2"  # ä½ çš„æ ¸å¿ƒæ–¹æ³•ï¼ˆç²‰è‰²çªå‡ºï¼‰
}
ALGORITHM_MARKERS = {
    "FedAvg": "o",
    "DP-FedAvg": "s",
    "FedProx": "^",
    "Ditto": "p",
    "FedShap": "*",
    "FedAdaClip++": "D",
    "FedFairADP-ALA": "X"  # ä½ çš„æ–¹æ³•æ ‡è®°ï¼ˆå‰å½¢ï¼Œçªå‡ºï¼‰
}

# ======================== é²æ£’æ€§åœºæ™¯é…ç½® ========================
SCALE_SCENARIOS = {"small": 10, "medium": 20, "large": 50}
NOISE_SCENARIOS = {"none": 0.0, "low": 0.1, "high": 0.3}
FAILURE_SCENARIOS = {"none": 0.0, "low": 0.1, "high": 0.2}
HETEROGENEITY_SCENARIOS = {"low": 0.2, "medium": 0.5, "high": 0.8}

# ======================== æ ¸å¿ƒå®éªŒç±» ========================
class EfficiencyRobustnessExperiment:
    def __init__(self, config=None, save_results=True, save_path="./experiment_results/efficiency_robustness"):
        self.config = config if config is not None else load_config()
        self.save_results = save_results
        self.save_path = save_path
        self.device = torch.device(self.config.device)
        self.process = psutil.Process(os.getpid())  # ç”¨äºèµ„æºç›‘æ§
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if self.save_results:
            os.makedirs(self.save_path, exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "plots"), exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "data"), exist_ok=True)
        
        # åˆå§‹åŒ–ç®—æ³•åˆ—è¡¨ï¼ˆé€‚é…ä½ çš„FederatedTrainerï¼‰
        self.algorithms = [
            {
                "name": "FedAvg",
                "type": "baseline",
                "run_func": self._run_baseline_algorithm
            },
            {
                "name": "DP-FedAvg",
                "type": "baseline",
                "run_func": self._run_baseline_algorithm
            },
            {
                "name": "FedProx",
                "type": "baseline",
                "run_func": self._run_baseline_algorithm
            },
            {
                "name": "Ditto",
                "type": "baseline",
                "run_func": self._run_baseline_algorithm
            },
            {
                "name": "FedShap",
                "type": "baseline",
                "run_func": self._run_baseline_algorithm
            },
            {
                "name": "FedAdaClip++",
                "type": "baseline",
                "run_func": self._run_baseline_algorithm
            },
            {
                "name": "FedFairADP-ALA",  # ä½ çš„æ ¸å¿ƒæ–¹æ³•
                "type": "custom",
                "run_func": self._run_fedfairadp_ala  # ä¸“ç”¨è¿è¡Œå‡½æ•°
            }
        ]
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = {
            "efficiency_metrics": {},  # æ•ˆç‡æŒ‡æ ‡
            "robustness_metrics": {},  # é²æ£’æ€§æŒ‡æ ‡
            "final_summary": {}        # æœ€ç»ˆæ±‡æ€»
        }
        
        print(f"âœ… æ•ˆç‡&é²æ£’æ€§å®éªŒåˆå§‹åŒ–å®Œæˆ | å¾…è¿è¡Œç®—æ³•ï¼š{[alg['name'] for alg in self.algorithms]}")

    # ======================== è¿è¡ŒåŸºçº¿ç®—æ³•ï¼ˆåŸæœ‰é€»è¾‘ï¼‰ ========================
    def _run_baseline_algorithm(self, alg_name, scenario_config=None):
        """è¿è¡ŒåŸæœ‰åŸºçº¿ç®—æ³•ï¼ˆFedAvg/DP-FedAvgç­‰ï¼‰"""
        start_time = time.time()
        client_params_sizes = []
        
        # é€‚é…åœºæ™¯é…ç½®ï¼ˆå¦‚å®¢æˆ·ç«¯æ•°é‡ã€å™ªå£°ç­‰ï¼‰
        if scenario_config:
            self.config.fed.num_clients = scenario_config.get("num_clients", self.config.fed.num_clients)
        
        # åˆå§‹åŒ–æœåŠ¡ç«¯
        if alg_name == "FedAvg":
            server = FedAvgServer(config=self.config, total_clients=self.config.fed.num_clients)
        elif alg_name == "DP-FedAvg":
            server = DPFedAvgServer(config=self.config, total_clients=self.config.fed.num_clients)
        elif alg_name == "FedProx":
            server = FedProxServer(config=self.config, total_clients=self.config.fed.num_clients)
        elif alg_name == "Ditto":
            server = DITTOServer(config=self.config, total_clients=self.config.fed.num_clients)
        elif alg_name == "FedShap":
            server = FedShapServer(config=self.config, total_clients=self.config.fed.num_clients)
        elif alg_name == "FedAdaClip++":
            server = FedAdaptiveDPServer(config=self.config, total_clients=self.config.fed.num_clients)
        server.global_model.to(self.device)
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        clients = {}
        for cid in range(self.config.fed.num_clients):
            if alg_name == "FedAvg":
                client = FedAvgClient(client_id=cid, config=self.config)
            elif alg_name == "DP-FedAvg":
                client = DPFedAvgClient(client_id=cid, config=self.config)
            elif alg_name == "FedProx":
                client = FedProxClient(client_id=cid, config=self.config)
            elif alg_name == "Ditto":
                client = DITTOClient(client_id=cid, config=self.config)
            elif alg_name == "FedShap":
                client = FedShapClient(client_id=cid, config=self.config)
            elif alg_name == "FedAdaClip++":
                client = FedAdaptiveDPClient(client_id=cid, config=self.config)
            client.local_model.to(self.device)
            clients[cid] = client
        server.clients = clients
        
        # è®­ç»ƒè¿‡ç¨‹
        global_acc_list = []
        for round_idx in range(self.config.fed.num_global_rounds):
            selected_cids = server.select_clients(round_idx=round_idx)
            client_outputs = []
            
            for cid in selected_cids:
                output = clients[cid].local_train()
                client_outputs.append(output)
                # è®°å½•å‚æ•°å¤§å°
                param_size = sum(p.numel() * p.element_size() for p in output)
                client_params_sizes.append(param_size)
            
            # èšåˆ
            if alg_name == "FedShap":
                server.aggregate_local_results(client_results_list=client_outputs)
            else:
                server.aggregate_local_results(client_params_list=client_outputs)
            
            # è¯„ä¼°
            acc, _ = server.evaluate_global_model()
            global_acc_list.append(acc)
        
        end_time = time.time()
        # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
        efficiency_metrics = calculate_efficiency_metrics(
            start_time=start_time,
            end_time=end_time,
            client_params_sizes=client_params_sizes,
            process=self.process
        )
        # è¿”å›ç»“æœ
        return {
            "efficiency": efficiency_metrics,
            "final_acc": global_acc_list[-1],
            "acc_list": global_acc_list
        }

    # ======================== è¿è¡Œä½ çš„FedFairADP-ALAï¼ˆæ ¸å¿ƒé€‚é…ï¼‰ ========================
    def _run_fedfairadp_ala(self, alg_name, scenario_config=None):
        """
        è¿è¡Œä½ çš„FedFairADP-ALAï¼ˆåŸºäºFederatedTrainerï¼‰
        """
        # å¤‡ä»½åŸå§‹é…ç½®
        original_num_clients = self.config.fed.num_clients
        
        # é€‚é…åœºæ™¯é…ç½®ï¼ˆå¦‚å®¢æˆ·ç«¯æ•°é‡ã€å™ªå£°ç­‰ï¼‰
        if scenario_config:
            self.config.fed.num_clients = scenario_config.get("num_clients", original_num_clients)
            # é€‚é…å™ªå£°/å¼‚æ„é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if "noise_level" in scenario_config:
                self.config.data.noise_level = scenario_config["noise_level"]
            if "heterogeneity_level" in scenario_config:
                self.config.data.heterogeneity_level = scenario_config["heterogeneity_level"]
        
        # åˆå§‹åŒ–ä½ çš„è”é‚¦è®­ç»ƒå™¨
        trainer = FederatedTrainer(config=self.config)
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        client_params_sizes = []  # ç”¨äºé€šä¿¡æ•ˆç‡è®¡ç®—
        
        try:
            # å¯åŠ¨è®­ç»ƒï¼ˆä½ çš„æ ¸å¿ƒé€»è¾‘ï¼‰
            trainer.run_federated_training()
            
            # æ”¶é›†å‚æ•°å¤§å°ï¼ˆæ¨¡æ‹Ÿï¼Œå®é™…å¯ä»trainerä¸­æå–ï¼‰
            for round_idx in range(self.config.fed.num_global_rounds):
                # å‡è®¾æ¯è½®å‚æ•°å¤§å°ï¼ˆå¯æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´ï¼‰
                param_size = sum(p.numel() * p.element_size() for p in trainer.server.global_model.parameters())
                client_params_sizes.append([param_size] * len(trainer.server.selected_clients))
            
            end_time = time.time()
            
            # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
            efficiency_metrics = calculate_efficiency_metrics(
                start_time=start_time,
                end_time=end_time,
                client_params_sizes=client_params_sizes,
                process=self.process
            )
            
            # æå–å…³é”®æŒ‡æ ‡
            final_acc = trainer.server.global_metrics["best_global_acc"] * 100  # è½¬ç™¾åˆ†æ¯”
            acc_list = [m["acc"] * 100 for m in trainer.server.global_metrics["round_metrics"]]
            
            # æ¢å¤åŸå§‹é…ç½®
            self.config.fed.num_clients = original_num_clients
            
            return {
                "efficiency": efficiency_metrics,
                "final_acc": final_acc,
                "acc_list": acc_list,
                "trainer_metrics": trainer.training_metrics  # ä½ çš„è®­ç»ƒå™¨ç›‘æ§æŒ‡æ ‡
            }
        
        except Exception as e:
            print(f"âŒ è¿è¡Œ{alg_name}å¤±è´¥ï¼š{str(e)}")
            # æ¢å¤åŸå§‹é…ç½®
            self.config.fed.num_clients = original_num_clients
            raise

    # ======================== é²æ£’æ€§æµ‹è¯•ï¼ˆå¤šåœºæ™¯ï¼‰ ========================
    def _test_robustness(self, alg_name, run_func):
        """æµ‹è¯•ç®—æ³•åœ¨ä¸åŒåœºæ™¯ä¸‹çš„é²æ£’æ€§"""
        # 1. è§„æ¨¡é²æ£’æ€§
        scale_perfs = []
        for scale, num_clients in SCALE_SCENARIOS.items():
            res = run_func(alg_name, scenario_config={"num_clients": num_clients})
            scale_perfs.append(res["final_acc"])
        
        # 2. å™ªå£°é²æ£’æ€§
        noise_perfs = []
        for noise, level in NOISE_SCENARIOS.items():
            res = run_func(alg_name, scenario_config={"noise_level": level})
            noise_perfs.append(res["final_acc"])
        
        # 3. æ•…éšœé²æ£’æ€§ï¼ˆæ¨¡æ‹Ÿ10%/20%å®¢æˆ·ç«¯æ•…éšœï¼‰
        failure_perfs = []
        for failure, rate in FAILURE_SCENARIOS.items():
            # æ¨¡æ‹Ÿæ•…éšœï¼šéšæœºé€‰æ‹©rateæ¯”ä¾‹çš„å®¢æˆ·ç«¯ä¸å‚ä¸è®­ç»ƒ
            res = run_func(alg_name, scenario_config={"failure_rate": rate})
            failure_perfs.append(res["final_acc"])
        
        # 4. å¼‚æ„é²æ£’æ€§
        hetero_perfs = []
        for hetero, level in HETEROGENEITY_SCENARIOS.items():
            res = run_func(alg_name, scenario_config={"heterogeneity_level": level})
            hetero_perfs.append(res["final_acc"])
        
        # è®¡ç®—é²æ£’æ€§æŒ‡æ ‡
        baseline_perf = scale_perfs[1]  # mediumè§„æ¨¡ä½œä¸ºåŸºå‡†
        robustness_metrics = {
            "scale": calculate_robustness_metrics(baseline_perf, scale_perfs),
            "noise": calculate_robustness_metrics(baseline_perf, noise_perfs),
            "failure": calculate_robustness_metrics(baseline_perf, failure_perfs),
            "heterogeneity": calculate_robustness_metrics(baseline_perf, hetero_perfs),
            # ç»¼åˆé²æ£’æ€§å¾—åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
            "comprehensive_score": np.mean([
                robustness_metrics["scale"]["robustness_score"],
                robustness_metrics["noise"]["robustness_score"],
                robustness_metrics["failure"]["robustness_score"],
                robustness_metrics["heterogeneity"]["robustness_score"]
            ])
        }
        
        return robustness_metrics

    # ======================== ä¸»è¿è¡Œé€»è¾‘ ========================
    def run(self):
        """è¿è¡Œæ‰€æœ‰ç®—æ³•çš„æ•ˆç‡&é²æ£’æ€§æµ‹è¯•"""
        for alg in self.algorithms:
            alg_name = alg["name"]
            run_func = alg["run_func"]
            
            print(f"\n========== å¼€å§‹æµ‹è¯• {alg_name} ==========")
            
            # 1. åŸºç¡€æ•ˆç‡æµ‹è¯•ï¼ˆåŸºå‡†åœºæ™¯ï¼‰
            baseline_res = run_func(alg_name)
            self.results["efficiency_metrics"][alg_name] = baseline_res["efficiency"]
            
            # 2. é²æ£’æ€§æµ‹è¯•
            robustness_metrics = self._test_robustness(alg_name, run_func)
            self.results["robustness_metrics"][alg_name] = robustness_metrics
            
            # 3. æ•´ç†æœ€ç»ˆæ±‡æ€»
            self.results["final_summary"][alg_name] = {
                "final_acc": baseline_res["final_acc"],
                "total_time": baseline_res["efficiency"]["total_time"],
                "avg_round_time": baseline_res["efficiency"]["avg_round_time"],
                "comprehensive_robustness_score": robustness_metrics["comprehensive_score"],
                "memory_usage_mb": baseline_res["efficiency"]["memory_usage_mb"],
                "total_comm_mb": baseline_res["efficiency"]["total_comm_mb"]
            }
            
            print(f"âœ… {alg_name} æµ‹è¯•å®Œæˆ | æœ€ç»ˆå‡†ç¡®ç‡ï¼š{baseline_res['final_acc']:.2f}% | é²æ£’æ€§å¾—åˆ†ï¼š{robustness_metrics['comprehensive_score']:.4f}")
        
        # ä¿å­˜ç»“æœ+ç”Ÿæˆå¯è§†åŒ–
        if self.save_results:
            self._save_results()
            self._generate_plots()
        
        # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        self._print_final_report()
        
        return self.results

    # ======================== ä¿å­˜ç»“æœ ========================
    def _save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # ä¿å­˜æ•ˆç‡æŒ‡æ ‡
        eff_df = pd.DataFrame.from_dict(self.results["efficiency_metrics"], orient="index")
        eff_df.to_csv(os.path.join(self.save_path, "data", "efficiency_metrics.csv"), encoding="utf-8")
        
        # ä¿å­˜é²æ£’æ€§æŒ‡æ ‡
        with open(os.path.join(self.save_path, "data", "robustness_metrics.json"), "w", encoding="utf-8") as f:
            json.dump(self.results["robustness_metrics"], f, ensure_ascii=False, indent=4)
        
        # ä¿å­˜æœ€ç»ˆæ±‡æ€»
        summary_df = pd.DataFrame.from_dict(self.results["final_summary"], orient="index")
        summary_df.to_csv(os.path.join(self.save_path, "data", "final_summary.csv"), encoding="utf-8")
        
        print(f"\nğŸ“ å®éªŒç»“æœå·²ä¿å­˜è‡³ï¼š{self.save_path}/data")

    # ======================== ç”Ÿæˆå¯è§†åŒ– ========================
    def _generate_plots(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        alg_names = list(self.results["final_summary"].keys())
        colors = [ALGORITHM_COLORS[alg] for alg in alg_names]
        
        # 1. ç»¼åˆé²æ£’æ€§å¾—åˆ†å¯¹æ¯”
        plt.figure(figsize=(12, 6))
        scores = [self.results["final_summary"][alg]["comprehensive_robustness_score"] for alg in alg_names]
        bars = plt.bar(alg_names, scores, color=colors, width=0.6)
        for bar, score in zip(bars, scores):
            plt.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.01, 
                     f"{score:.4f}", ha="center", va="bottom")
        plt.xlabel("ç®—æ³•", fontsize=12)
        plt.ylabel("ç»¼åˆé²æ£’æ€§å¾—åˆ†ï¼ˆ0~1ï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•ç»¼åˆé²æ£’æ€§å¾—åˆ†å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.ylim(0, 1.1)
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", f"robustness_score_comparison.{PLOT_FORMAT}"), 
                    dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 2. æ€»è®­ç»ƒè€—æ—¶å¯¹æ¯”
        plt.figure(figsize=(12, 6))
        total_times = [self.results["final_summary"][alg]["total_time"] for alg in alg_names]
        bars = plt.bar(alg_names, total_times, color=colors, width=0.6)
        for bar, t in zip(bars, total_times):
            plt.text(bar.get_x()+bar.get_width()/2, bar.get_height()+1, 
                     f"{t:.2f}s", ha="center", va="bottom")
        plt.xlabel("ç®—æ³•", fontsize=12)
        plt.ylabel("æ€»è®­ç»ƒè€—æ—¶ï¼ˆç§’ï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•æ€»è®­ç»ƒè€—æ—¶å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", f"total_time_comparison.{PLOT_FORMAT}"), 
                    dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 3. æœ€ç»ˆå‡†ç¡®ç‡+é²æ£’æ€§æ•£ç‚¹å›¾
        plt.figure(figsize=(10, 8))
        final_accs = [self.results["final_summary"][alg]["final_acc"] for alg in alg_names]
        scores = [self.results["final_summary"][alg]["comprehensive_robustness_score"] for alg in alg_names]
        
        for i, alg in enumerate(alg_names):
            plt.scatter(final_accs[i], scores[i], 
                        color=ALGORITHM_COLORS[alg],
                        marker=ALGORITHM_MARKERS[alg],
                        s=150, label=alg)
            # æ ‡æ³¨ç®—æ³•å
            plt.text(final_accs[i]+0.5, scores[i]+0.01, alg, fontsize=9)
        
        plt.xlabel("æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡ï¼ˆ%ï¼‰", fontsize=12)
        plt.ylabel("ç»¼åˆé²æ£’æ€§å¾—åˆ†ï¼ˆ0~1ï¼‰", fontsize=12)
        plt.title("å„ç®—æ³•å‡†ç¡®ç‡-é²æ£’æ€§å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.save_path, "plots", f"acc_robustness_scatter.{PLOT_FORMAT}"), 
                    dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ï¼š{self.save_path}/plots")

    # ======================== æ‰“å°æœ€ç»ˆæŠ¥å‘Š ========================
    def _print_final_report(self):
        """æ‰“å°æœ€ç»ˆå¯¹æ¯”æŠ¥å‘Š"""
        print("\n========== æ•ˆç‡&é²æ£’æ€§å®éªŒ - æœ€ç»ˆæŠ¥å‘Š ==========")
        print(f"{'ç®—æ³•':<15} {'æœ€ç»ˆå‡†ç¡®ç‡(%)':<15} {'æ€»è€—æ—¶(s)':<15} {'é²æ£’æ€§å¾—åˆ†':<15} {'å†…å­˜å ç”¨(MB)':<15} {'é€šä¿¡å¼€é”€(MB)':<15}")
        print("-" * 100)
        for alg_name, summary in self.results["final_summary"].items():
            print(
                f"{alg_name:<15} "
                f"{summary['final_acc']:<15.2f} "
                f"{summary['total_time']:<15.2f} "
                f"{summary['comprehensive_robustness_score']:<15.4f} "
                f"{summary['memory_usage_mb']:<15.2f} "
                f"{summary['total_comm_mb']:<15.2f}"
            )
        print("-" * 100)

# ======================== å·¥å…·å‡½æ•°ï¼ˆå¤ç”¨ï¼‰ ========================
def calculate_efficiency_metrics(start_time: float, end_time: float, 
                                 client_params_sizes: List[int], 
                                 process: psutil.Process) -> Dict:
    """è®¡ç®—æ•ˆç‡æŒ‡æ ‡"""
    total_time = end_time - start_time
    num_rounds = len(client_params_sizes) if client_params_sizes else 0
    avg_round_time = total_time / num_rounds if num_rounds > 0 else 0.0
    
    memory_usage = process.memory_info().rss / (1024 * 1024)
    cpu_usage = process.cpu_percent()
    gpu_memory = 0.0
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.max_memory_allocated() / (1024 * 1024)
    
    total_comm_bytes = sum([sum(sizes) for sizes in client_params_sizes]) if client_params_sizes else 0.0
    total_comm_mb = total_comm_bytes / (1024 * 1024)
    avg_round_comm_mb = total_comm_mb / num_rounds if num_rounds > 0 else 0.0
    
    return {
        "total_time": float(total_time),
        "avg_round_time": float(avg_round_time),
        "memory_usage_mb": float(memory_usage),
        "cpu_usage_pct": float(cpu_usage),
        "gpu_memory_mb": float(gpu_memory),
        "total_comm_mb": float(total_comm_mb),
        "avg_round_comm_mb": float(avg_round_comm_mb)
    }

def calculate_robustness_metrics(baseline_perf: float, perturbed_perfs: List[float]) -> Dict:
    """è®¡ç®—é²æ£’æ€§æŒ‡æ ‡"""
    perf_retention_rates = [perf / baseline_perf * 100 for perf in perturbed_perfs if baseline_perf != 0]
    avg_retention_rate = np.mean(perf_retention_rates) if perf_retention_rates else 0.0
    perf_std = np.std(perturbed_perfs)
    perf_cv = perf_std / np.mean(perturbed_perfs) if np.mean(perturbed_perfs) != 0 else 0.0
    robustness_score = (avg_retention_rate / 100) * (1 - perf_cv)
    robustness_score = np.clip(robustness_score, 0, 1)
    
    return {
        "baseline_perf": float(baseline_perf),
        "perturbed_perfs": [float(p) for p in perturbed_perfs],
        "avg_retention_rate_pct": float(avg_retention_rate),
        "perf_std": float(perf_std),
        "perf_cv": float(perf_cv),
        "robustness_score": float(robustness_score)
    }

# ======================== å¤–éƒ¨è°ƒç”¨å‡½æ•° ========================
def run_efficiency_robustness_experiment(config=None, save_results=True, save_path="./experiment_results/efficiency_robustness"):
    experiment = EfficiencyRobustnessExperiment(config=config, save_results=save_results, save_path=save_path)
    results = experiment.run()
    return results

# ======================== ä¸»å‡½æ•° ========================
if __name__ == "__main__":
    results = run_efficiency_robustness_experiment(
        save_results=True,
        save_path="./experiment_results/efficiency_robustness_2026"
    )
    print("\nâœ… æ•ˆç‡&é²æ£’æ€§å®éªŒå…¨éƒ¨å®Œæˆï¼")