# experiments/ablation_study.py
"""
FedFairADP-ALA æ ¸å¿ƒæ¨¡å—æ¶ˆèå®éªŒè„šæœ¬
æ ¸å¿ƒç›®æ ‡ï¼š
1. æ¶ˆèFedFairADP-ALAçš„5å¤§æ ¸å¿ƒæ¨¡å—ï¼ŒéªŒè¯æ¯ä¸ªæ¨¡å—çš„å¿…è¦æ€§å’Œæ”¶ç›Šï¼š
   - å˜ä½“1ï¼šç§»é™¤ALAï¼ˆAdaptive Local Adjustmentï¼‰â†’ æœ¬åœ°ä»…æ™®é€šSGDæ›´æ–°
   - å˜ä½“2ï¼šç§»é™¤ä¼ªæ ‡ç­¾ â†’ ä»…ç”¨çœŸå®æ ‡ç­¾è®­ç»ƒï¼Œæ— é«˜ç½®ä¿¡ä¼ªæ ‡ç­¾è¡¥å……
   - å˜ä½“3ï¼šç§»é™¤å…¬å¹³é€‰æ‹© â†’ éšæœºé€‰æ‹©å®¢æˆ·ç«¯ï¼Œæ— æ•°æ®å¤šæ ·æ€§-å‚ä¸é¢‘ç‡ç­›é€‰
   - å˜ä½“4ï¼šShapleyèšåˆâ†’å…¨å±€å¹³å‡èšåˆ â†’ æ— è¾¹é™…è´¡çŒ®é‡åŒ–
   - å˜ä½“5ï¼šè‡ªé€‚åº”è£å‰ªDPâ†’å›ºå®šè£å‰ªDP â†’ æ— Shapleyå€¼é©±åŠ¨çš„è£å‰ªè°ƒæ•´
2. ä¸¥æ ¼éµå¾ªå•ä¸€å˜é‡åŸåˆ™ï¼šä»…å…³é—­ç›®æ ‡æ¨¡å—ï¼Œå…¶ä½™å‚æ•°/æµç¨‹ä¸åŸºå‡†ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼›
3. è®°å½•æ ¸å¿ƒæŒ‡æ ‡ï¼ˆæ€§èƒ½ï¼šå‡†ç¡®ç‡/æŸå¤±ï¼›å…¬å¹³æ€§ï¼šåŸºå°¼ç³»æ•°ï¼›éšç§ï¼šÎµæœ‰æ•ˆå€¼ï¼›æ•ˆç‡ï¼šè€—æ—¶ï¼‰ï¼›
4. è¾“å‡ºæ¶ˆèå¯¹æ¯”æŠ¥å‘Šã€é‡åŒ–æ”¶ç›Šåˆ†æå’Œå¯è§†åŒ–å›¾è¡¨ï¼Œæ˜ç¡®å„æ¨¡å—çš„ç‹¬ç«‹è´¡çŒ®ã€‚
è®¾è®¡åŸåˆ™ï¼š
- åŸºäºä½ çš„FederatedTraineræ¡†æ¶ï¼Œä»…ä¿®æ”¹ç›®æ ‡æ¨¡å—é€»è¾‘ï¼Œä¿è¯å®éªŒä¸€è‡´æ€§ï¼›
- æ¯ä¸ªå˜ä½“ä»…å·®å¼‚ç›®æ ‡æ¨¡å—ï¼Œå…¶ä½™é€»è¾‘ï¼ˆå¦‚å…¶ä»–æ¨¡å—ã€è®­ç»ƒå‚æ•°ï¼‰å®Œå…¨å¯¹é½ï¼›
- ç»“æœç»“æ„åŒ–ä¿å­˜ï¼Œæ”¯æŒé‡åŒ–åˆ†æå„æ¨¡å—çš„è´¡çŒ®åº¦ã€‚
"""
import os
import time
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import random

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from configs.config_loader import load_config
from core.federated.trainer import FederatedTrainer
from core.federated.server import BaseServer
from core.federated.client import BaseClient
from core.dp.adaptive_clipping_dp import AdaptiveClippingDP
from core.shapley.shapley_calculator import ShapleyCalculator

# å¯è§†åŒ–é…ç½®
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False
PLOT_FORMAT = "png"
PLOT_DPI = 300
# é¢œè‰²æ˜ å°„ï¼šåŸºå‡†ç‰ˆæœ¬ï¼ˆä½ çš„å®Œæ•´æ–¹æ³•ï¼‰vs æ¶ˆèå˜ä½“
COLOR_MAP = {
    "åŸºå‡†ç‰ˆæœ¬ï¼ˆFedFairADP-ALAï¼‰": "#1f77b4",
    "å˜ä½“1ï¼ˆç§»é™¤ALAï¼‰": "#ff7f0e",
    "å˜ä½“2ï¼ˆç§»é™¤ä¼ªæ ‡ç­¾ï¼‰": "#2ca02c",
    "å˜ä½“3ï¼ˆç§»é™¤å…¬å¹³é€‰æ‹©ï¼‰": "#d62728",
    "å˜ä½“4ï¼ˆå¹³å‡èšåˆï¼‰": "#9467bd",
    "å˜ä½“5ï¼ˆå›ºå®šè£å‰ªDPï¼‰": "#8c564b"
}
MARKER_MAP = {
    "åŸºå‡†ç‰ˆæœ¬ï¼ˆFedFairADP-ALAï¼‰": "o",
    "å˜ä½“1ï¼ˆç§»é™¤ALAï¼‰": "s",
    "å˜ä½“2ï¼ˆç§»é™¤ä¼ªæ ‡ç­¾ï¼‰": "^",
    "å˜ä½“3ï¼ˆç§»é™¤å…¬å¹³é€‰æ‹©ï¼‰": "p",
    "å˜ä½“4ï¼ˆå¹³å‡èšåˆï¼‰": "*",
    "å˜ä½“5ï¼ˆå›ºå®šè£å‰ªDPï¼‰": "D"
}

# ======================== æ¶ˆèå˜ä½“å®šä¹‰ï¼ˆæ ¸å¿ƒï¼šå•ä¸€å˜é‡ï¼‰ ========================
# æ¯ä¸ªå˜ä½“ä»…ä¿®æ”¹ç›®æ ‡æ¨¡å—ï¼Œå…¶ä½™é€»è¾‘ä¸åŸºå‡†ç‰ˆæœ¬å®Œå…¨ä¸€è‡´
ABLATION_VARIANTS = [
    {
        "name": "åŸºå‡†ç‰ˆæœ¬ï¼ˆFedFairADP-ALAï¼‰",
        "description": "å®Œæ•´çš„FedFairADP-ALAï¼ˆåŒ…å«æ‰€æœ‰æ ¸å¿ƒæ¨¡å—ï¼‰",
        "modify_func": None,  # æ— ä¿®æ”¹
        "focus_metrics": ["performance", "fairness", "privacy", "efficiency"]
    },
    {
        "name": "å˜ä½“1ï¼ˆç§»é™¤ALAï¼‰",
        "description": "ç§»é™¤è‡ªé€‚åº”å±€éƒ¨è°ƒæ•´ï¼ˆALAï¼‰ï¼Œæœ¬åœ°ä»…ç”¨æ™®é€šSGDæ›´æ–°",
        "modify_func": "disable_ala",
        "focus_metrics": ["performance", "stability"]
    },
    {
        "name": "å˜ä½“2ï¼ˆç§»é™¤ä¼ªæ ‡ç­¾ï¼‰",
        "description": "ç§»é™¤é«˜ç½®ä¿¡ä¼ªæ ‡ç­¾è¡¥å……ï¼Œä»…ç”¨çœŸå®æ ‡ç­¾è®­ç»ƒ",
        "modify_func": "disable_pseudo_label",
        "focus_metrics": ["performance", "data_efficiency"]
    },
    {
        "name": "å˜ä½“3ï¼ˆç§»é™¤å…¬å¹³é€‰æ‹©ï¼‰",
        "description": "å®¢æˆ·ç«¯éšæœºé€‰æ‹©ï¼Œæ— æ•°æ®å¤šæ ·æ€§-å‚ä¸é¢‘ç‡ç­›é€‰",
        "modify_func": "disable_fair_selection",
        "focus_metrics": ["fairness", "performance"]
    },
    {
        "name": "å˜ä½“4ï¼ˆå¹³å‡èšåˆï¼‰",
        "description": "Shapleyè¾¹é™…è´¡çŒ®èšåˆ â†’ å…¨å±€ç­‰æƒé‡å¹³å‡èšåˆ",
        "modify_func": "disable_shapley_aggregate",
        "focus_metrics": ["fairness", "performance"]
    },
    {
        "name": "å˜ä½“5ï¼ˆå›ºå®šè£å‰ªDPï¼‰",
        "description": "Shapleyé©±åŠ¨çš„è‡ªé€‚åº”è£å‰ªDP â†’ å›ºå®šè£å‰ªé˜ˆå€¼DP",
        "modify_func": "disable_adaptive_clip_dp",
        "focus_metrics": ["privacy", "performance"]
    }
]

# ======================== æ¶ˆèå˜ä½“ä¿®æ”¹é€»è¾‘ï¼ˆæ ¸å¿ƒï¼šå•ä¸€å˜é‡ï¼‰ ========================
class AblationClient(BaseClient):
    """å¸¦æ¶ˆèå¼€å…³çš„å®¢æˆ·ç«¯ç±»ï¼ˆä»…ä¿®æ”¹ç›®æ ‡æ¨¡å—ï¼Œå…¶ä½™é€»è¾‘ä¸BaseClientä¸€è‡´ï¼‰"""
    def __init__(self, client_id, config, dataset, ablation_config=None):
        super().__init__(client_id, config, dataset)
        self.ablation_config = ablation_config or {}
        
    # å˜ä½“1ï¼šç§»é™¤ALAï¼ˆè‡ªé€‚åº”å±€éƒ¨è°ƒæ•´ï¼‰
    def local_train(self):
        if self.ablation_config.get("disable_ala"):
            # æ™®é€šSGDæ›´æ–°ï¼ˆæ— ALAè‡ªé€‚åº”è°ƒæ•´ï¼‰
            self._local_train_basic_sgd()
        else:
            # åŸå§‹ALAè‡ªé€‚åº”å±€éƒ¨è°ƒæ•´
            super().local_train()
    
    def _local_train_basic_sgd(self):
        """æ™®é€šSGDæœ¬åœ°è®­ç»ƒï¼ˆæ— ALAï¼‰"""
        self.local_model.train()
        optimizer = torch.optim.SGD(self.local_model.parameters(), lr=self.config.train.lr)
        criterion = self.config.train.criterion
        
        for epoch in range(self.config.train.local_epochs):
            for data, target in self.dataset.train_loader:
                data, target = data.to(self.device), target.to(self.device)
                optimizer.zero_grad()
                output = self.local_model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
        
        self.local_train_loss = loss.item()
    
    # å˜ä½“2ï¼šç§»é™¤ä¼ªæ ‡ç­¾
    def _generate_pseudo_labels(self):
        if self.ablation_config.get("disable_pseudo_label"):
            # ä¸ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç›´æ¥è¿”å›ç©º
            return None
        else:
            # åŸå§‹ä¼ªæ ‡ç­¾ç”Ÿæˆé€»è¾‘
            return super()._generate_pseudo_labels()

class AblationServer(BaseServer):
    """å¸¦æ¶ˆèå¼€å…³çš„æœåŠ¡ç«¯ç±»ï¼ˆä»…ä¿®æ”¹ç›®æ ‡æ¨¡å—ï¼Œå…¶ä½™é€»è¾‘ä¸BaseServerä¸€è‡´ï¼‰"""
    def __init__(self, config, total_clients, ablation_config=None):
        super().__init__(config, total_clients)
        self.ablation_config = ablation_config or {}
        self.shapley_calculator = ShapleyCalculator(config=config)
        
    # å˜ä½“3ï¼šç§»é™¤å…¬å¹³é€‰æ‹©ï¼ˆéšæœºé€‰æ‹©å®¢æˆ·ç«¯ï¼‰
    def select_clients(self, round_idx):
        if self.ablation_config.get("disable_fair_selection"):
            # éšæœºé€‰æ‹©å®¢æˆ·ç«¯ï¼ˆæ— å…¬å¹³æ€§ç­›é€‰ï¼‰
            num_select = int(self.config.fed.client_selection_ratio * self.total_clients)
            selected_cids = random.sample(range(self.total_clients), num_select)
            return selected_cids
        else:
            # åŸå§‹å…¬å¹³é€‰æ‹©é€»è¾‘ï¼ˆæ•°æ®å¤šæ ·æ€§+å‚ä¸é¢‘ç‡ï¼‰
            return super().select_clients(round_idx)
    
    # å˜ä½“4ï¼šShapleyèšåˆâ†’å¹³å‡èšåˆ
    def aggregate_local_results(self):
        if self.ablation_config.get("disable_shapley_aggregate"):
            # ç­‰æƒé‡å¹³å‡èšåˆ
            client_params = [self.client_uploads[cid]["params"] for cid in self.client_uploads.keys()]
            avg_params = self._average_params(client_params)
            return avg_params
        else:
            # åŸå§‹Shapleyè¾¹é™…è´¡çŒ®èšåˆ
            return super().aggregate_local_results()
    
    def _average_params(self, params_list):
        """ç­‰æƒé‡å¹³å‡èšåˆï¼ˆæ— Shapleyï¼‰"""
        avg_params = []
        for param_tensors in zip(*params_list):
            avg_tensor = torch.mean(torch.stack(param_tensors), dim=0)
            avg_params.append(avg_tensor)
        return avg_params
    
    # å˜ä½“5ï¼šè‡ªé€‚åº”è£å‰ªDPâ†’å›ºå®šè£å‰ªDP
    def init_dp_optimizer(self):
        if self.ablation_config.get("disable_adaptive_clip_dp"):
            # å›ºå®šè£å‰ªé˜ˆå€¼DP
            self.dp_optimizer = AdaptiveClippingDP(config=self.config)
            self.dp_optimizer.adaptive = False  # å…³é—­è‡ªé€‚åº”
            self.dp_optimizer.clip_threshold = self.config.dp.fixed_clip_threshold  # å›ºå®šé˜ˆå€¼
        else:
            # åŸå§‹Shapleyé©±åŠ¨çš„è‡ªé€‚åº”è£å‰ªDP
            super().init_dp_optimizer()

class AblationFederatedTrainer(FederatedTrainer):
    """å¸¦æ¶ˆèé…ç½®çš„è”é‚¦è®­ç»ƒå™¨ï¼ˆä»…æ›¿æ¢Server/Clientä¸ºæ¶ˆèç‰ˆæœ¬ï¼‰"""
    def __init__(self, config, ablation_config=None):
        super().__init__(config)
        self.ablation_config = ablation_config or {}
    
    # é‡å†™å®¢æˆ·ç«¯åˆå§‹åŒ–ï¼šä½¿ç”¨AblationClient
    def init_clients(self):
        logger.info(f"ğŸ“Œ åˆå§‹åŒ–æ¶ˆèå®éªŒå®¢æˆ·ç«¯ï¼ˆé…ç½®ï¼š{self.ablation_config}ï¼‰...")
        self.clients = {}
        
        for client_id in range(self.total_clients):
            try:
                client_dataset = get_client_dataset(config=self.config, client_id=client_id)
                # ä½¿ç”¨æ¶ˆèå®¢æˆ·ç«¯
                client = AblationClient(
                    client_id=client_id,
                    config=self.config,
                    dataset=client_dataset,
                    ablation_config=self.ablation_config
                )
                self.clients[client_id] = client
            except Exception as e:
                logger.error(f"âŒ å®¢æˆ·ç«¯[{client_id}]åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
                self.training_metrics["failed_client_ids"].append(client_id)
    
    # é‡å†™æœåŠ¡ç«¯åˆå§‹åŒ–ï¼šä½¿ç”¨AblationServer
    def init_server(self):
        logger.info(f"ğŸ“Œ åˆå§‹åŒ–æ¶ˆèå®éªŒæœåŠ¡ç«¯ï¼ˆé…ç½®ï¼š{self.ablation_config}ï¼‰...")
        try:
            # ä½¿ç”¨æ¶ˆèæœåŠ¡ç«¯
            self.server = AblationServer(
                config=self.config,
                total_clients=self.total_clients,
                ablation_config=self.ablation_config
            )
            self.global_test_dataloader = get_global_test_dataset(config=self.config).get_dataloader()
        except Exception as e:
            raise RuntimeError(f"æœåŠ¡ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}") from e

# ======================== æ ¸å¿ƒå®éªŒç±» ========================
class FedFairADPAlaAblationExperiment:
    def __init__(self, config=None, save_results=True, save_path="./experiment_results/ablation_study_fedfairadp"):
        self.config = config if config is not None else load_config()
        self.save_results = save_results
        self.save_path = save_path
        self.device = torch.device(self.config.device)
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if self.save_results:
            os.makedirs(self.save_path, exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "plots"), exist_ok=True)
            os.makedirs(os.path.join(self.save_path, "data"), exist_ok=True)
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = {
            "variant_metrics": {},  # æ¯ä¸ªå˜ä½“çš„è¯¦ç»†æŒ‡æ ‡
            "gain_analysis": {}     # å„æ¨¡å—çš„æ”¶ç›Šåˆ†æ
        }
        
        print(f"âœ… FedFairADP-ALAæ¶ˆèå®éªŒåˆå§‹åŒ–å®Œæˆ | å¾…è¿è¡Œå˜ä½“æ•°ï¼š{len(ABLATION_VARIANTS)}")
        print(f"ğŸ“Œ å®éªŒé…ç½®ï¼šå…¨å±€è½®æ¬¡={self.config.fed.num_global_rounds} | å®¢æˆ·ç«¯æ•°={self.config.fed.num_clients}")

    def _run_variant(self, variant):
        """è¿è¡Œå•ä¸ªæ¶ˆèå˜ä½“ï¼ˆä¸¥æ ¼å•ä¸€å˜é‡ï¼‰"""
        variant_name = variant["name"]
        modify_func = variant["modify_func"]
        print(f"\n--- è¿è¡Œå˜ä½“ï¼š{variant_name} ---")
        print(f"å˜ä½“æè¿°ï¼š{variant['description']}")
        
        # 1. æ„å»ºæ¶ˆèé…ç½®ï¼ˆä»…è®¾ç½®ç›®æ ‡æ¨¡å—çš„å…³é—­å¼€å…³ï¼‰
        ablation_config = {}
        if modify_func:
            ablation_config[modify_func] = True
        
        # 2. åˆå§‹åŒ–å¸¦æ¶ˆèé…ç½®çš„è®­ç»ƒå™¨
        trainer = AblationFederatedTrainer(
            config=self.config,
            ablation_config=ablation_config
        )
        
        # 3. è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # 4. å¯åŠ¨è®­ç»ƒï¼ˆä¸åŸºå‡†ç‰ˆæœ¬æµç¨‹å®Œå…¨ä¸€è‡´ï¼‰
        trainer.run_federated_training()
        
        # 5. è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        total_time = end_time - start_time
        avg_round_time = np.mean(trainer.training_metrics["round_duration"])
        
        # 6. æå–æ ¸å¿ƒæŒ‡æ ‡
        # æ€§èƒ½æŒ‡æ ‡
        global_acc_list = [m["acc"] * 100 for m in trainer.server.global_metrics["round_metrics"]]
        global_loss_list = [m["loss"] for m in trainer.server.global_metrics["round_metrics"]]
        final_global_acc = trainer.server.global_metrics["best_global_acc"] * 100
        final_global_loss = trainer.server.global_metrics["best_global_loss"]
        
        # å…¬å¹³æ€§æŒ‡æ ‡ï¼ˆåŸºå°¼ç³»æ•°ï¼‰
        client_accs = [trainer.clients[cid].evaluate_local_model() for cid in trainer.clients.keys()]
        final_gini = self._calculate_gini(client_accs)
        
        # éšç§æŒ‡æ ‡ï¼ˆDP Îµå€¼ï¼‰
        avg_dp_epsilon = 0.0
        if hasattr(trainer.server, "dp_optimizer"):
            avg_dp_epsilon = trainer.server.dp_optimizer.calculate_epsilon()
        
        # 7. æ•´ç†ç»“æœ
        variant_results = {
            "global_acc": global_acc_list,
            "global_loss": global_loss_list,
            "final_global_acc": final_global_acc,
            "final_global_loss": final_global_loss,
            "final_gini": final_gini,
            "avg_dp_epsilon": avg_dp_epsilon,
            "total_time": total_time,
            "avg_round_time": avg_round_time,
            "best_round": trainer.server.global_metrics["best_round"],
            "client_train_success": sum(trainer.training_metrics["client_train_success"]),
            "description": variant["description"]
        }
        
        print(f"âœ… å˜ä½“ {variant_name} è¿è¡Œå®Œæˆ | æœ€ç»ˆå‡†ç¡®ç‡ï¼š{final_global_acc:.2f}% | åŸºå°¼ç³»æ•°ï¼š{final_gini:.4f} | æ€»è€—æ—¶ï¼š{total_time:.2f}s")
        return variant_results

    def _calculate_gini(self, values):
        """è®¡ç®—åŸºå°¼ç³»æ•°ï¼ˆè¡¡é‡å®¢æˆ·ç«¯å‡†ç¡®ç‡å…¬å¹³æ€§ï¼Œè¶Šå°è¶Šå…¬å¹³ï¼‰"""
        if len(values) == 0:
            return 0.0
        values = np.array(values)
        values = np.sort(values)
        n = len(values)
        if values.sum() == 0:
            return 0.0
        cumsum = np.cumsum(values)
        return (n + 1 - 2 * np.sum(cumsum) / cumsum[-1]) / n

    def _calculate_module_gain(self, baseline_results, variant_results, focus_metrics):
        """è®¡ç®—å•ä¸ªæ¨¡å—çš„æ”¶ç›Šï¼ˆåŸºå‡† - å˜ä½“ï¼Œå€¼è¶Šå¤§æ¨¡å—è´¡çŒ®è¶Šé«˜ï¼‰"""
        gain = {}
        # æ€§èƒ½æ”¶ç›Š
        if "performance" in focus_metrics:
            gain["accuracy_gain"] = baseline_results["final_global_acc"] - variant_results["final_global_acc"]
            gain["loss_reduction"] = variant_results["final_global_loss"] - baseline_results["final_global_loss"]
        # å…¬å¹³æ€§æ”¶ç›Š
        if "fairness" in focus_metrics:
            gain["gini_reduction"] = variant_results["final_gini"] - baseline_results["final_gini"]
        # éšç§æ”¶ç›Šï¼ˆÎµè¶Šå°è¶Šå¥½ï¼‰
        if "privacy" in focus_metrics:
            gain["epsilon_reduction"] = variant_results["avg_dp_epsilon"] - baseline_results["avg_dp_epsilon"]
        # æ•ˆç‡æ”¶ç›Š
        if "efficiency" in focus_metrics:
            gain["time_reduction"] = variant_results["total_time"] - baseline_results["total_time"]
        return gain

    def run(self):
        """è¿è¡Œæ‰€æœ‰æ¶ˆèå˜ä½“ï¼Œè®¡ç®—æ¨¡å—æ”¶ç›Š"""
        # 1. å…ˆè¿è¡ŒåŸºå‡†ç‰ˆæœ¬ï¼ˆå¿…é¡»ç¬¬ä¸€ä¸ªè¿è¡Œï¼Œä½œä¸ºæ”¶ç›Šè®¡ç®—çš„åŸºå‡†ï¼‰
        baseline_variant = ABLATION_VARIANTS[0]
        baseline_results = self._run_variant(baseline_variant)
        self.results["variant_metrics"][baseline_variant["name"]] = baseline_results
        
        # 2. è¿è¡Œæ‰€æœ‰æ¶ˆèå˜ä½“
        for variant in ABLATION_VARIANTS[1:]:
            variant_results = self._run_variant(variant)
            self.results["variant_metrics"][variant["name"]] = variant_results
            
            # 3. è®¡ç®—è¯¥æ¨¡å—çš„æ”¶ç›Š
            gain = self._calculate_module_gain(baseline_results, variant_results, variant["focus_metrics"])
            self.results["gain_analysis"][variant["name"]] = gain
        
        # 4. ä¿å­˜ç»“æœ+ç”Ÿæˆå¯è§†åŒ–
        if self.save_results:
            self._save_results()
            self._generate_plots()
        
        # 5. è¾“å‡ºæ¶ˆèæŠ¥å‘Š
        self._print_ablation_report()
        
        return self.results

    def _save_results(self):
        """ä¿å­˜æ¶ˆèå®éªŒç»“æœ"""
        # 1. å˜ä½“è¯¦ç»†æŒ‡æ ‡ï¼ˆJSONï¼‰
        metrics_path = os.path.join(self.save_path, "data", "variant_metrics.json")
        with open(metrics_path, "w", encoding="utf-8") as f:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            serializable_results = {}
            for var_name, metrics in self.results["variant_metrics"].items():
                serializable_metrics = {k: (v.tolist() if isinstance(v, np.ndarray) else v) for k, v in metrics.items()}
                serializable_results[var_name] = serializable_metrics
            json.dump(serializable_results, f, ensure_ascii=False, indent=4)
        
        # 2. æ¨¡å—æ”¶ç›Šåˆ†æï¼ˆCSVï¼‰
        gain_df = pd.DataFrame.from_dict(self.results["gain_analysis"], orient="index")
        gain_df.reset_index(inplace=True)
        gain_df.rename(columns={"index": "variant"}, inplace=True)
        gain_path = os.path.join(self.save_path, "data", "gain_analysis.csv")
        gain_df.to_csv(gain_path, index=False, encoding="utf-8")
        
        print(f"\nğŸ“ æ¶ˆèå®éªŒç»“æœå·²ä¿å­˜è‡³ï¼š{self.save_path}/data")

    def _generate_plots(self):
        """ç”Ÿæˆæ¶ˆèå®éªŒå¯è§†åŒ–å›¾è¡¨"""
        variants = list(self.results["variant_metrics"].keys())
        rounds = list(range(1, self.config.fed.num_global_rounds + 1))
        
        # 1. å…¨å±€å‡†ç¡®ç‡æ”¶æ•›æ›²çº¿ï¼ˆæ ¸å¿ƒå¯¹æ¯”ï¼‰
        plt.figure(figsize=(14, 8))
        for var_name in variants:
            metrics = self.results["variant_metrics"][var_name]
            plt.plot(
                rounds, metrics["global_acc"],
                label=var_name,
                color=COLOR_MAP[var_name],
                marker=MARKER_MAP[var_name],
                markersize=6,
                linewidth=2
            )
        plt.xlabel("å…¨å±€è½®æ¬¡", fontsize=12)
        plt.ylabel("å…¨å±€å‡†ç¡®ç‡ï¼ˆ%ï¼‰", fontsize=12)
        plt.title("FedFairADP-ALAå„æ¶ˆèå˜ä½“å‡†ç¡®ç‡æ”¶æ•›å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.legend(fontsize=10, loc="lower right")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", "accuracy_convergence.png")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 2. æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
        plt.figure(figsize=(14, 7))
        final_accs = [self.results["variant_metrics"][var]["final_global_acc"] for var in variants]
        colors = [COLOR_MAP[var] for var in variants]
        
        bars = plt.bar(variants, final_accs, color=colors, width=0.6)
        for bar, acc in zip(bars, final_accs):
            plt.text(
                bar.get_x() + bar.get_width()/2,
                bar.get_height() + 0.3,
                f"{acc:.2f}%",
                ha="center", va="bottom", fontsize=9
            )
        plt.xlabel("æ¶ˆèå˜ä½“", fontsize=12)
        plt.ylabel("æœ€ç»ˆå…¨å±€å‡†ç¡®ç‡ï¼ˆ%ï¼‰", fontsize=12)
        plt.title("FedFairADP-ALAå„æ¶ˆèå˜ä½“æœ€ç»ˆå‡†ç¡®ç‡å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.xticks(rotation=15, ha="right")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", "final_accuracy_comparison.png")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        # 3. å…¬å¹³æ€§ï¼ˆåŸºå°¼ç³»æ•°ï¼‰å¯¹æ¯”
        plt.figure(figsize=(14, 7))
        gini_values = [self.results["variant_metrics"][var]["final_gini"] for var in variants]
        bars = plt.bar(variants, gini_values, color=colors, width=0.6)
        
        for bar, gini in zip(bars, gini_values):
            plt.text(
                bar.get_x() + bar.get_width()/2,
                bar.get_height() + 0.005,
                f"{gini:.4f}",
                ha="center", va="bottom", fontsize=9
            )
        plt.xlabel("æ¶ˆèå˜ä½“", fontsize=12)
        plt.ylabel("æœ€ç»ˆåŸºå°¼ç³»æ•°ï¼ˆè¶Šå°è¶Šå…¬å¹³ï¼‰", fontsize=12)
        plt.title("FedFairADP-ALAå„æ¶ˆèå˜ä½“å…¬å¹³æ€§å¯¹æ¯”", fontsize=14, fontweight="bold")
        plt.xticks(rotation=15, ha="right")
        plt.grid(True, alpha=0.3, axis="y")
        plt.tight_layout()
        plot_path = os.path.join(self.save_path, "plots", "gini_coefficient_comparison.png")
        plt.savefig(plot_path, dpi=PLOT_DPI, bbox_inches="tight")
        plt.close()
        
        print(f"ğŸ“Š æ¶ˆèå®éªŒå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ï¼š{self.save_path}/plots")

    def _print_ablation_report(self):
        """æ‰“å°æ¶ˆèå®éªŒæœ€ç»ˆæŠ¥å‘Šï¼ˆé‡åŒ–å„æ¨¡å—è´¡çŒ®ï¼‰"""
        print("\n" + "="*100)
        print("FedFairADP-ALA æ ¸å¿ƒæ¨¡å—æ¶ˆèå®éªŒ - æœ€ç»ˆæŠ¥å‘Š")
        print("="*100)
        print(f"{'å˜ä½“åç§°':<25} {'æœ€ç»ˆå‡†ç¡®ç‡(%)':<15} {'åŸºå°¼ç³»æ•°':<15} {'DP Îµå€¼':<15} {'æ€»è€—æ—¶(s)':<15} {'æ¨¡å—æ”¶ç›Š(%)':<15}")
        print("-"*100)
        
        # åŸºå‡†ç‰ˆæœ¬ç»“æœ
        baseline_name = ABLATION_VARIANTS[0]["name"]
        baseline_acc = self.results["variant_metrics"][baseline_name]["final_global_acc"]
        
        for var_name in variants:
            if var_name == baseline_name:
                module_gain = "åŸºå‡†"
            else:
                module_gain = f"{baseline_acc - self.results['variant_metrics'][var_name]['final_global_acc']:.2f}"
            
            metrics = self.results["variant_metrics"][var_name]
            print(
                f"{var_name:<25} "
                f"{metrics['final_global_acc']:<15.2f} "
                f"{metrics['final_gini']:<15.4f} "
                f"{metrics['avg_dp_epsilon']:<15.2f} "
                f"{metrics['total_time']:<15.2f} "
                f"{module_gain:<15}"
            )
        
        print("-"*100)
        print("æ¨¡å—æ”¶ç›Šè¯´æ˜ï¼š")
        print("1. æ¨¡å—æ”¶ç›Š = åŸºå‡†ç‰ˆæœ¬å‡†ç¡®ç‡ - æ¶ˆèå˜ä½“å‡†ç¡®ç‡ â†’ å€¼è¶Šå¤§ï¼Œè¯¥æ¨¡å—å¯¹æ€§èƒ½çš„è´¡çŒ®è¶Šé«˜ï¼›")
        print("2. åŸºå°¼ç³»æ•°è¶Šå° â†’ å®¢æˆ·ç«¯å‡†ç¡®ç‡åˆ†å¸ƒè¶Šå…¬å¹³ï¼›")
        print("3. DP Îµå€¼è¶Šå° â†’ éšç§ä¿æŠ¤æ•ˆæœè¶Šå¥½ï¼›")
        print("4. æ‰€æœ‰å˜ä½“ä»…ä¿®æ”¹ç›®æ ‡æ¨¡å—ï¼Œå…¶ä½™é€»è¾‘ä¸åŸºå‡†ç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼Œä¿è¯å•ä¸€å˜é‡åŸåˆ™ã€‚")
        print("="*100)

# ======================== å¤–éƒ¨è°ƒç”¨å‡½æ•° ========================
def run_fedfairadp_ala_ablation(config=None, save_results=True, save_path="./experiment_results/ablation_study_fedfairadp"):
    """è¿è¡ŒFedFairADP-ALAæ ¸å¿ƒæ¨¡å—æ¶ˆèå®éªŒ"""
    experiment = FedFairADPAlaAblationExperiment(config=config, save_results=save_results, save_path=save_path)
    results = experiment.run()
    return results

# ======================== ä¸»å‡½æ•° ========================
if __name__ == "__main__":
    # è¡¥å……ç¼ºå¤±çš„å¯¼å…¥ï¼ˆä¸ä½ çš„trainerä¿æŒä¸€è‡´ï¼‰
    from datasets import get_client_dataset, get_global_test_dataset
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("AblationExperiment")
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    results = run_fedfairadp_ala_ablation(
        save_results=True,
        save_path="./experiment_results/ablation_study_fedfairadp_2026"
    )
    print("\nâœ… FedFairADP-ALAæ ¸å¿ƒæ¨¡å—æ¶ˆèå®éªŒå…¨éƒ¨å®Œæˆï¼")